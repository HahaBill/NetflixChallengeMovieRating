{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender systems\n",
    "\n",
    "- Implementing collaborative filtering and latent factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import random\n",
    "from random import randint\n",
    "from random import uniform\n",
    "import operator\n",
    "from operator import itemgetter\n",
    "print(np.version.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3262092\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "### NOTES\n",
    "This file is an example of what your code should look like. It is written in Python 3.6.\n",
    "To know more about the expectations, please refer to the guidelines.\n",
    "\"\"\"\n",
    "\n",
    "#####\n",
    "##\n",
    "## DATA IMPORT\n",
    "##\n",
    "#####\n",
    "\n",
    "#Where data is located\n",
    "movies_file = '../data/movies.csv'\n",
    "users_file = '../data/users.csv'\n",
    "ratings_file = '../data/ratings.csv'\n",
    "predictions_file = '../data/predictions.csv'\n",
    "submission_file = '../data/submission.csv'\n",
    "\n",
    "# movies_file = r'/prediction/data/movies.csv'\n",
    "# users_file = '/prediction/data/users.csv'\n",
    "# ratings_file = '/prediction/data/ratings.csv'\n",
    "# predictions_file = '/prediction/data/predictions.csv'\n",
    "# submission_file = '/data/submission.csv'\n",
    "\n",
    "# Read the data using pandas\n",
    "movies_description = pd.read_csv(movies_file, delimiter=';', \n",
    "                                 dtype={'movieID':'int', 'year':'int', 'movie':'str'}, names=['movieID', 'year', 'movie'])\n",
    "users_description = pd.read_csv(users_file, delimiter=';', \n",
    "                                dtype={'userID':'int', 'gender':'str', 'age':'int', 'profession':'int'}, names=['userID', 'gender', 'age', 'profession'])\n",
    "ratings_description = pd.read_csv(ratings_file, delimiter=';', \n",
    "                                  dtype={'userID':'int', 'movieID':'int', 'rating':'int'}, names=['userID', 'movieID', 'rating'])\n",
    "predictions_description = pd.read_csv(predictions_file, delimiter=';', names=['userID', 'movieID'], header=None)\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "##\n",
    "## COLLABORATIVE FILTERING\n",
    "##\n",
    "#####\n",
    "\n",
    "'''\n",
    "Computing cosine similarity\n",
    "'''\n",
    "def cosine_similarity(a, b):\n",
    "    denominator = np.linalg.norm(a)*np.linalg.norm(b)\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    \n",
    "    return np.dot(a, b) / denominator\n",
    "\n",
    "'''\n",
    "Creating similarity matrix with cosine similarity\n",
    "'''\n",
    "def similarity_matrix_with_cosine(ratingMatrix):\n",
    "    number_items = np.shape(ratingMatrix)[0]\n",
    "    similarity_matrix = np.zeros((number_items, number_items), dtype=object)\n",
    "    \n",
    "    for i in range(number_items):\n",
    "        print(i)\n",
    "        for j in range(i, number_items):\n",
    "            \n",
    "            movieID = j + 1\n",
    "            similarity_matrix[i][j] = (movieID, cosine_similarity(ratingMatrix[:, i], ratingMatrix[:, j]))\n",
    "            similarity_matrix[j][i] = similarity_matrix[i][j]\n",
    "   \n",
    "    return similarity_matrix\n",
    "\n",
    "def sum_of_squares(ratings_with_prediction):\n",
    "    \n",
    "    error_rating_col = ratings_with_prediction.apply(lambda row: np.square(row['predicted_rating'] - row['rating']), axis = 1)\n",
    "    sse_error = error_rating_col.sum()\n",
    "    \n",
    "    return sse_error\n",
    "        \n",
    "# def interpolation_weights_optimization():\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def predict_collaborative_filtering(movies, users, ratings, predictions):\n",
    "    \n",
    "    # Processing predictions data in order to return it from this function\n",
    "    number_predictions = len(predictions)\n",
    "    prediction_creating = [[idx, random.uniform(0, 5)] for idx in range(1, number_predictions + 1)]\n",
    "    predictions_ratings = pd.DataFrame(prediction_creating, columns = ['Id', 'Rating'])\n",
    "    predictions_ratings['movieID'] = predictions['movieID']\n",
    "    predictions_ratings['userID'] = predictions['userID']\n",
    "    \n",
    "    # Adding missing movie_ids to the numpy arrays\n",
    "    range_missing = range(3696, 3707)\n",
    "    \n",
    "    '''\n",
    "    Creating utility matrix 'u' : User x Movie -> Rating\n",
    "    '''        \n",
    "    utility_matrix = ratings.pivot_table(index='movieID', columns='userID', values='rating', fill_value=0)\n",
    "    \n",
    "    original_rating = utility_matrix.values\n",
    "    for i, row in utility_matrix.iterrows():\n",
    "        if(i in range_missing):\n",
    "            original_rating = np.vstack([original_rating, row.values])\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Creating matrix for cosine similarity\n",
    "    '''\n",
    "    r = ratings \\\n",
    "    .groupby('movieID', as_index=False, sort=False) \\\n",
    "    .mean() \\\n",
    "    .rename(columns={'movieID': 'movieID', 'rating' : 'mean_rating'})\n",
    "    r.drop('userID', axis=1, inplace=True)\n",
    "    \n",
    "    new_r = ratings.merge(r, how='left', on='movieID', sort=False)\n",
    "    new_r['centered_cosine'] = new_r['rating'] - new_r['mean_rating']\n",
    "    \n",
    "    centered_cosine = new_r \\\n",
    "    .pivot_table(index='movieID', columns='userID', values='centered_cosine') \\\n",
    "    .fillna(0)\n",
    "    \n",
    "    \n",
    "    all_movies_numpy = centered_cosine.values\n",
    "    for i, row in centered_cosine.iterrows():\n",
    "        if(i in range_missing):\n",
    "            all_movies_numpy = np.vstack([all_movies_numpy, row.values])\n",
    "            \n",
    "    # Similarity matrix\n",
    "    similarity_matrix = similarity_matrix_with_cosine(all_movies_numpy)\n",
    "    \n",
    "    # Average rating\n",
    "    mean_all_ratings = ratings['rating'].mean()\n",
    "    \n",
    "    '''\n",
    "    Cosine similarity - find similar users for a certain user based on |N|,\n",
    "    also making a prediction with Pearson correlation\n",
    "    '''\n",
    "    for i, user_movie in predictions.iterrows():\n",
    "        current_rating = original_rating[user_movie['movieID'] - 1][user_movie['userID'] - 1]\n",
    "        if (current_rating > 0):\n",
    "            predictions_ratings.at[i, 'Rating'] = current_rating\n",
    "            continue\n",
    "        \n",
    "        print(\" \")\n",
    "        print(\" \")\n",
    "        print(\"NEW PREDICTION\", i)\n",
    "        user_calculate_mean = original_rating[:, user_movie['userID'] - 1]\n",
    "        movie_calculate_mean = original_rating[user_movie['movieID'] - 1, :]\n",
    "        \n",
    "        mean_user_rating = user_calculate_mean[np.nonzero(user_calculate_mean)].mean()\n",
    "        mean_movie_rating = movie_calculate_mean[np.nonzero(movie_calculate_mean)].mean()\n",
    "        \n",
    "        b_x = mean_user_rating - mean_all_ratings\n",
    "        b_i = mean_movie_rating - mean_all_ratings\n",
    "        print(\"B_X : \", b_x)\n",
    "        print(\"B_I : \", b_i)\n",
    "        print(\" \")\n",
    "        \n",
    "        # Get N similar items\n",
    "        top_N_similar_movies = sorted(similarity_matrix[user_movie['movieID'] - 1], key=lambda pair: pair[1], reverse=True)\n",
    "        similar_movies = top_N_similar_movies[1:4]\n",
    "        \n",
    "        #Predicting the rating with Pearson correlation\n",
    "        pearson_denominator = 0\n",
    "        #sum([pair[1] for pair in similar_movies])\n",
    "        for i, pair in enumerate(similar_movies):\n",
    "            #if(original_rating[similar_movies[i][0] - 1][user_movie['userID'] - 1] != 0):\n",
    "            pearson_denominator += similar_movies[i][1]\n",
    "        \n",
    "        pearson_numerator = 0\n",
    "        for i in range(0, 3):\n",
    "            \n",
    "            calculate_similar_movie = original_rating[similar_movies[i][0] - 1, :]\n",
    "            mean_similar_movie = calculate_similar_movie[np.nonzero(calculate_similar_movie)].mean()\n",
    "                \n",
    "            b_xj = mean_similar_movie - mean_all_ratings \n",
    "            pearson_numerator += similar_movies[i][1] * (original_rating[similar_movies[i][0] - 1]\n",
    "                                                             [user_movie['userID'] - 1] - b_xj)\n",
    "        \n",
    "        final_prediction = mean_all_ratings + b_x + b_i + (pearson_numerator / pearson_denominator)\n",
    "        print(\"Final prediction : \", final_prediction)\n",
    "        print(\" \")\n",
    "        if(final_prediction < 1):\n",
    "            predictions_ratings.at[i, 'Rating'] = 1\n",
    "        elif (final_prediction > 5):\n",
    "            predictions_ratings.at[i, 'Rating'] = 5\n",
    "        else:\n",
    "            predictions_ratings.at[i, 'Rating'] = final_prediction\n",
    "        print(\"---\")\n",
    "        print(\"Predicted rating : \", predictions_ratings.at[i, 'Rating'])\n",
    "        print(\"---\")\n",
    "        print(\" \")\n",
    "    \n",
    "    return predictions_ratings\n",
    "\n",
    "\n",
    "#####\n",
    "##\n",
    "## LATENT FACTORS\n",
    "##\n",
    "#####\n",
    "\n",
    "def predict_latent_factors(movies, users, ratings, predictions):\n",
    "    ## TO COMPLETE\n",
    "    \n",
    "    # Processing predictions data in order to return it from this function\n",
    "    number_predictions = len(predictions)\n",
    "    prediction_creating = [[idx, random.uniform(0, 5)] for idx in range(1, number_predictions + 1)]\n",
    "    predictions_ratings = pd.DataFrame(prediction_creating, columns = ['Id', 'Rating'])\n",
    "    predictions_ratings['movieID'] = predictions['movieID']\n",
    "    predictions_ratings['userID'] = predictions['userID']\n",
    "    \n",
    "    # Adding missing movie_ids to the numpy arrays\n",
    "    range_missing = range(3696, 3707)\n",
    "    \n",
    "    '''\n",
    "    Creating utility matrix 'u' : User x Movie -> Rating\n",
    "    '''        \n",
    "    utility_matrix = ratings.pivot_table(index='movieID', columns='userID', values='rating', fill_value=0)\n",
    "    \n",
    "    original_rating = utility_matrix.values\n",
    "    for i, row in utility_matrix.iterrows():\n",
    "        if(i in range_missing):\n",
    "            original_rating = np.vstack([original_rating, row.values])\n",
    "            \n",
    "    '''\n",
    "    Utility matrix with subtracted mean of the rating per movie\n",
    "    '''\n",
    "    r = ratings \\\n",
    "    .groupby('movieID', as_index=False, sort=False) \\\n",
    "    .mean() \\\n",
    "    .rename(columns={'movieID': 'movieID', 'rating' : 'mean_rating'})\n",
    "    r.drop('userID', axis=1, inplace=True)\n",
    "    \n",
    "    new_r = ratings.merge(r, how='left', on='movieID', sort=False)\n",
    "    new_r['centered_cosine'] = new_r['rating'] - new_r['mean_rating']\n",
    "    \n",
    "    centered_cosine = new_r \\\n",
    "    .pivot_table(index='movieID', columns='userID', values='centered_cosine') \\\n",
    "    .fillna(0)\n",
    "    \n",
    "    \n",
    "    all_movies_numpy = centered_cosine.values\n",
    "    for i, row in centered_cosine.iterrows():\n",
    "        if(i in range_missing):\n",
    "            all_movies_numpy = np.vstack([all_movies_numpy, row.values])\n",
    "    \n",
    "    # Doing Matrix factorization Q * PT\n",
    "    U, S, VT = np.linalg.svd(original_rating, full_matrices=False)\n",
    "    \n",
    "    Q = U\n",
    "    S_diagonal = np.diag(S)\n",
    "    P = S_diagonal.dot(VT)\n",
    "    \n",
    "    # Predicting rating\n",
    "    for i, user_movie in predictions.iterrows():\n",
    "            \n",
    "        qi = Q[user_movie['movieID'] - 1, :]\n",
    "        px = P[:, user_movie['userID'] - 1]\n",
    "        \n",
    "        print(qi.dot(px))\n",
    "        predictions_ratings.at[i, 'Rating'] = qi.dot(px)\n",
    " \n",
    "    \n",
    "    return predictions_ratings\n",
    "    \n",
    "\n",
    "\n",
    "#####\n",
    "##\n",
    "## FINAL PREDICTORS\n",
    "##\n",
    "#####\n",
    "\n",
    "def predict_final(movies, users, ratings, predictions):\n",
    "    ## TO COMPLETE\n",
    "    \n",
    "    '''\n",
    "    Splitting known ratings into training and test data\n",
    "    '''\n",
    "    split_data = np.random.rand(len(ratings)) < 0.7\n",
    "    train_data = ratings[split_data]\n",
    "    test_data = ratings[~split_data]\n",
    "    \n",
    "    ratings['predicted_rating'] = np.random.randint(1, 6, ratings.shape[0])\n",
    "    \n",
    "    sse = sum_of_squares(ratings)\n",
    "    print(sse)\n",
    "\n",
    "\n",
    "# rating_predictions = predict_collaborative_filtering(movies_description,\n",
    "#                                                      users_description, ratings_description, predictions_description)\n",
    "# rating_predictions.drop('userID', axis=1, inplace=True)\n",
    "# rating_predictions.drop('movieID', axis=1, inplace=True)\n",
    "\n",
    "#latent_factors_ratings = predict_latent_factors(movies_description,\n",
    "#                                                 users_description, ratings_description, predictions_description)\n",
    "predict_final(movies_description, users_description, ratings_description, predictions_description)\n",
    "#####\n",
    "##\n",
    "## RANDOM PREDICTORS\n",
    "## //!!\\\\ TO CHANGE\n",
    "##\n",
    "#####\n",
    "\n",
    "#By default, predicted rate is a random classifier\n",
    "def predict_random(movies, users, ratings, predictions):\n",
    "    number_predictions = len(predictions)\n",
    "\n",
    "    return [[idx, randint(1, 5)] for idx in range(1, number_predictions + 1)]\n",
    "\n",
    "#####\n",
    "##\n",
    "## SAVE RESULTS\n",
    "##\n",
    "#####    \n",
    "\n",
    "\n",
    "# ## //!!\\\\ TO CHANGE by your prediction function\n",
    "submission_read = pd.read_csv(submission_file)\n",
    "submission_read.columns = ['id', 'rating']\n",
    "\n",
    "# predictions = predict_random(movies_description, users_description, ratings_description, predictions_description)\n",
    "# print(predictions)\n",
    "# predictions_df = pd.DataFrame(predictions, columns = ['Id', 'Rating'])\n",
    "\n",
    "submission_result = submission_read.merge(rating_predictions, how='left', left_on='id', right_on='Id')\n",
    "submission_result.drop('id', axis=1, inplace=True)\n",
    "submission_result.drop('rating', axis=1, inplace=True)\n",
    "submission_result.head()\n",
    "submission_result.to_csv('submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_read = pd.read_csv(submission_file)\n",
    "submission_read.to_csv('submission_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
