{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender systems\n",
    "\n",
    "- Implementing collaborative filtering and latent factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import random\n",
    "from random import randint\n",
    "from random import uniform\n",
    "print(np.version.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "### NOTES\n",
    "This file is an example of what your code should look like. It is written in Python 3.6.\n",
    "To know more about the expectations, please refer to the guidelines.\n",
    "\"\"\"\n",
    "\n",
    "#####\n",
    "##\n",
    "## DATA IMPORT\n",
    "##\n",
    "#####\n",
    "\n",
    "#Where data is located\n",
    "movies_file = '../data/movies.csv'\n",
    "users_file = '../data/users.csv'\n",
    "ratings_file = '../data/ratings.csv'\n",
    "predictions_file = '../data/predictions.csv'\n",
    "submission_file = '../data/submission.csv'\n",
    "\n",
    "# movies_file = r'/prediction/data/movies.csv'\n",
    "# users_file = '/prediction/data/users.csv'\n",
    "# ratings_file = '/prediction/data/ratings.csv'\n",
    "# predictions_file = '/prediction/data/predictions.csv'\n",
    "# submission_file = '/data/submission.csv'\n",
    "\n",
    "# Read the data using pandas\n",
    "movies_description = pd.read_csv(movies_file, delimiter=';', \n",
    "                                 dtype={'movieID':'int', 'year':'int', 'movie':'str'}, names=['movieID', 'year', 'movie'])\n",
    "users_description = pd.read_csv(users_file, delimiter=';', \n",
    "                                dtype={'userID':'int', 'gender':'str', 'age':'int', 'profession':'int'}, names=['userID', 'gender', 'age', 'profession'])\n",
    "ratings_description = pd.read_csv(ratings_file, delimiter=';', \n",
    "                                  dtype={'userID':'int', 'movieID':'int', 'rating':'float64'}, names=['userID', 'movieID', 'rating'])\n",
    "predictions_description = pd.read_csv(predictions_file, delimiter=';', \n",
    "                                      dtype={'userID':'int', 'movieID':'int'}, names=['userID', 'movieID'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS USELESS, THIS IS JUST TO SAVE MY CUSTOM PEARSON CORRELATION\n",
    "\n",
    "def pearson(r1, r2, min_len):\n",
    "     \n",
    "    # Removing all zero elements from both arrays\n",
    "    r1zero = np.where(r1 == 0)[0]\n",
    "    r2zero = np.where(r2 == 0)[0]\n",
    "    r_1 = np.delete(r1, r2zero)\n",
    "    r_2 = np.delete(r2, r1zero)\n",
    "    r_1 = r_1[r_1 != 0]\n",
    "    r_2 = r_2[r_2 != 0]\n",
    "#     print(\"RESULTS SHOULD BE: \", stats.pearsonr(r_1, r_2))\n",
    "\n",
    "\n",
    "    # test if arrays only have a few elements in common that aren't 0\n",
    "    if len(r_1) < min_len:\n",
    "        return None\n",
    "    \n",
    "    top = np.sum((r_1 - np.mean(r_1)) * (r_2 - np.mean(r_2)))\n",
    "    botleft = np.sqrt(np.sum(np.square(r_1 - np.mean(r_1))))\n",
    "    botright = np.sqrt(np.sum(np.square(r_2 - np.mean(r_2))))\n",
    "    if botleft * botright == 0:\n",
    "        return None\n",
    "    res = top / (botleft * botright)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "##\n",
    "## COLLABORATIVE FILTERING\n",
    "##\n",
    "#####\n",
    "\n",
    "# minimal elements to have a rating on for two movies to be considered a neighbour. \n",
    "# Otherwise a movie with one rating and rest all zeroes is a good neighbour to all movies with that rating by that one user\n",
    "\n",
    "def predict_collaborative_filtering(movies, users, ratings, predictions, neighbours, min_periods, print_output = False):\n",
    "    \n",
    "    predictions_ratings = []\n",
    "    \n",
    "    \n",
    "#     Creating utility matrix 'u' : User x Movie -> Rating \n",
    "    utility_matrix = ratings.pivot_table(index='movieID', columns='userID', values='rating',\n",
    "                                         fill_value=0)\n",
    "    utility_matrix_none = ratings.pivot_table(index='userID', columns='movieID', values='rating',\n",
    "                                         fill_value=None)\n",
    " \n",
    "    # Add columns to the utility matrix for movies that are never rated\n",
    "    cols = utility_matrix_none.columns\n",
    "    for i in movies['movieID'].values:\n",
    "        if i not in cols:\n",
    "            utility_matrix_none[str(i)] = np.nan\n",
    "\n",
    "        \n",
    "    corr = utility_matrix_none.corr(min_periods=min_periods)\n",
    "    \n",
    "    # I don't know why, but somehow saving this in a csv and loading it back up again fixes some errors\n",
    "    corr.to_csv(r'tempcorr.csv')\n",
    "    corr = pd.read_csv(r'tempcorr.csv')\n",
    "\n",
    "    if print_output:\n",
    "        print(\"\\n>>>UTILITY MATRIX\\n\")\n",
    "        print(utility_matrix_none)\n",
    "        print(\"\\n>>>CORR MATRIX\\n\")\n",
    "        print(corr)\n",
    "        print(\"\\n>>>TO PREDICT\")\n",
    "        print(predictions)\n",
    "        print(\"\\n\\n>>>STARTING PREDICTION \\n\\n\")\n",
    "    \n",
    "    # For every prediction to make (item/item, or movie/movie in this case)\n",
    "    for i in range(len(predictions)):\n",
    "#         if i % 100 == 0:\n",
    "#             print(i, \"/\", len(predictions))\n",
    "        user = predictions.iloc[i][0]\n",
    "        movie = predictions.iloc[i][1]\n",
    "          \n",
    "        \n",
    "        c = corr[['movieID', str(movie)]]\n",
    "        \n",
    "        # Sort the pearson correlation for all movies to the current movie to predict\n",
    "        sorted_pearson = c.sort_values(by = [str(movie)], axis = 0, ascending = False)\n",
    "        \n",
    "        # Delete the movie itself, it should not be checked\n",
    "        sorted_pearson = sorted_pearson[sorted_pearson.movieID != movie]\n",
    "        \n",
    "        # Get the movie id's of the sorted movies\n",
    "        sorted_movies = sorted_pearson['movieID'].values\n",
    "        sorted_corr = sorted_pearson[str(movie)].values\n",
    "        \n",
    "        # Add a certain amount of neirest neighbours, this amount is specified by the n_neighbours variable\n",
    "        relevant_ratings = []\n",
    "        for m in range(0, len(sorted_movies)):\n",
    "            mov = sorted_movies[m]\n",
    "            rating = utility_matrix_none.at[user, mov]\n",
    "            if not np.isnan(rating):\n",
    "                relevant_ratings.append((rating, sorted_corr[m]))\n",
    "                if len(relevant_ratings) == neighbours:\n",
    "                    break\n",
    "        \n",
    "        relevant_ratings = np.array(relevant_ratings)\n",
    "        \n",
    "        total_weight = np.sum(relevant_ratings, axis = 0)[1]\n",
    "        pred = 0\n",
    "        for j in range(len(relevant_ratings)):\n",
    "            pred += relevant_ratings[j, 0] * relevant_ratings[j, 1] / total_weight\n",
    "        \n",
    "        # If the rating can't be calculated, set it to 3 as average\n",
    "        if np.isnan(pred) or pred == 0:\n",
    "            pred = 2.5\n",
    "        \n",
    "        if print_output:\n",
    "            print(\"\\n>>>>>>>>>>>>STARTING PREDICTION NUMBER\", i + 1, \"\\nUser:\", user, \"\\nMovie:\", movie, \"\\n\")\n",
    "            print(\"\\n>>SORTED PEARSON CORRELATION MATRIX\\n\")\n",
    "            print(sorted_pearson)\n",
    "            print(\"\\n>>RELEVANT RATINGS AND THEIR WEIGHTS\\n\")\n",
    "            print(relevant_ratings)\n",
    "            print(\"\\n>>FINAL PREDICTION: \", pred)\n",
    "        predictions_ratings.append((i + 1, pred))\n",
    "    return predictions_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      movieID      1914\n",
      "1533     1539  1.000000\n",
      "379       380  1.000000\n",
      "1905     1914  1.000000\n",
      "1968     1977  0.975665\n",
      "3161     3172  0.973329\n",
      "...       ...       ...\n",
      "3701     1642       NaN\n",
      "3702     1645       NaN\n",
      "3703     2395       NaN\n",
      "3704     3153       NaN\n",
      "3705     3226       NaN\n",
      "\n",
      "[3706 rows x 2 columns]\n",
      "      movieID      1914\n",
      "1533     1539  1.000000\n",
      "379       380  1.000000\n",
      "1968     1977  0.975665\n",
      "3161     3172  0.973329\n",
      "177       178  0.968330\n",
      "...       ...       ...\n",
      "3701     1642       NaN\n",
      "3702     1645       NaN\n",
      "3703     2395       NaN\n",
      "3704     3153       NaN\n",
      "3705     3226       NaN\n",
      "\n",
      "[3705 rows x 2 columns]\n",
      "      movieID      2124\n",
      "2115     2124  1.000000\n",
      "3682     3694  1.000000\n",
      "3052     3062  0.988212\n",
      "3107     3117  0.968246\n",
      "7           8  0.968246\n",
      "...       ...       ...\n",
      "3701     1642       NaN\n",
      "3702     1645       NaN\n",
      "3703     2395       NaN\n",
      "3704     3153       NaN\n",
      "3705     3226       NaN\n",
      "\n",
      "[3706 rows x 2 columns]\n",
      "      movieID      2124\n",
      "3682     3694  1.000000\n",
      "3052     3062  0.988212\n",
      "3107     3117  0.968246\n",
      "7           8  0.968246\n",
      "2648     2658  0.962250\n",
      "...       ...       ...\n",
      "3701     1642       NaN\n",
      "3702     1645       NaN\n",
      "3703     2395       NaN\n",
      "3704     3153       NaN\n",
      "3705     3226       NaN\n",
      "\n",
      "[3705 rows x 2 columns]\n",
      "[(1, 2.424532191861358), (2, 2.7619720753020918)]\n"
     ]
    }
   ],
   "source": [
    "# Predict the submission and put it in csv\n",
    "min_elements_non_zero = 5\n",
    "n_neighbours = 5\n",
    "\n",
    "predictions = predict_collaborative_filtering(movies_description,\n",
    "                                                     users_description, ratings_description, predictions_description.head, n_neighbours, min_elements_non_zero)\n",
    "print(predictions)\n",
    "predictions_df = pd.DataFrame(predictions, columns = ['Id', 'Rating'])\n",
    "predictions_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with test 1 / 169  Time =  09:42:01\n"
     ]
    }
   ],
   "source": [
    "#delete import later\n",
    "from datetime import datetime\n",
    "\n",
    "# Creates random test prediction scores (so we can test our RMSE)\n",
    "def create_random_tests(ratings, amount, seed):\n",
    "    if seed != -1:\n",
    "        random.seed(seed)\n",
    "    predictions = []\n",
    "    solutions = []\n",
    "    for i in range(amount):\n",
    "        r = random.randint(0, 910189)\n",
    "        predictions.append(ratings.loc[r][0:2])\n",
    "        solutions.append(ratings.loc[r][2])\n",
    "    predictions_df = pd.DataFrame(predictions, columns = ['userID', 'movieID'], dtype = 'int')\n",
    "    \n",
    "    return (predictions_df, solutions)\n",
    "\n",
    "\n",
    "# Calculates root mean squared error\n",
    "def rmse(pred, sol):\n",
    "    return np.sqrt(((np.array(pred) - np.array(sol)) ** 2).mean())\n",
    "\n",
    "# Runs the create tests method, and then executes these tests\n",
    "def run_tests(amount, seed = -1, neighbours = [5], min_periods = [5]):\n",
    "    (random_test_predictions, random_test_solutions) = create_random_tests(ratings_description, amount, seed = seed)\n",
    "    test_results = []\n",
    "    \n",
    "    total_tests = len(neighbours) * len(min_periods)\n",
    "    curr_test = 1\n",
    "    # For each pair of neighbour/min_period, get the rmse of the result\n",
    "    for n in neighbours:\n",
    "        for p in min_periods:\n",
    "            predictions = predict_collaborative_filtering(movies_description,\n",
    "                                                     users_description, ratings_description, random_test_predictions, n, p)\n",
    "            predictions = [x[1] for x in predictions]\n",
    "            test_results.append((n, p, seed, rmse(predictions, random_test_solutions)))\n",
    "            \n",
    "            #print the time, so we know how long it takes, delete later\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            \n",
    "            print(\"Done with test\", curr_test, \"/\", total_tests, \" Time = \", current_time)\n",
    "            curr_test += 1\n",
    "            \n",
    "    return pd.DataFrame(test_results, columns = ['n_neighbours', 'min_periods', 'seed', 'rmse'], dtype = 'int')\n",
    "\n",
    "\n",
    "neighbours_to_test = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "min_periods_to_test = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "test_results = run_tests(100, seed = 42, neighbours = neighbours_to_test, min_periods = min_periods_to_test)\n",
    "test_results.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     '''\n",
    "#     Creating matrix for cosine similarity\n",
    "#     '''\n",
    "#     r = ratings \\\n",
    "#     .groupby('movieID', as_index=False, sort=False) \\\n",
    "#     .mean() \\\n",
    "#     .rename(columns={'movieID': 'movieID', 'rating' : 'mean_rating'})\n",
    "#     r.drop('userID', axis=1, inplace=True)\n",
    "    \n",
    "#     new_r = ratings.merge(r, how='left', on='movieID', sort=False)\n",
    "#     new_r['centered_cosine'] = new_r['rating'] - new_r['mean_rating']\n",
    "    \n",
    "#     centered_cosine = new_r \\\n",
    "#     .pivot_table(index='movieID', columns='userID', values='centered_cosine') \\\n",
    "#     .fillna(0)\n",
    "    \n",
    "    \n",
    "#     all_movies_numpy = centered_cosine.values\n",
    "#     for i, row in centered_cosine.iterrows():\n",
    "#         if(i in range_missing):\n",
    "#             all_movies_numpy = np.vstack([all_movies_numpy, row.values])\n",
    "            \n",
    "            \n",
    "#     '''\n",
    "#     Cosine similarity - find similar users for a certain user based on |N|,\n",
    "#     also making a prediction with Pearson correlation\n",
    "#     '''\n",
    "#     for i, user_movie in predictions.iterrows():\n",
    "#         print(\"CURRENT MOVIE : \", user_movie['movieID'])\n",
    "#         current_movie = all_movies_numpy[user_movie['movieID'] - 1]\n",
    "#         current_rating = original_rating[user_movie['movieID'] - 1][user_movie['userID'] - 1]\n",
    "#         if(current_rating > 0):\n",
    "#              predictions_ratings.at[i, 'Rating'] = current_rating\n",
    "#              continue\n",
    "        \n",
    "#         current_denominator = np.sqrt(sum([np.square(x) for x in current_movie]))\n",
    "#         top_N_similar_movies = []\n",
    "        \n",
    "#         # Computing similarities to current movie that we want to predict for particular user\n",
    "#         for id_movie, movie in enumerate(all_movies_numpy):\n",
    "            \n",
    "#             numerator = [x*y for x, y in zip(current_movie, movie)]\n",
    "#             other_denominator = np.sqrt(sum([np.square(x) for x in movie]))\n",
    "#             costheta = sum(numerator) / (current_denominator * other_denominator)\n",
    "#             top_N_similar_movies.append((id_movie + 1, costheta))\n",
    "            \n",
    "#         # Get N similar items\n",
    "#         top_N_similar_movies.sort(key=lambda pair: pair[1], reverse=True)\n",
    "#         similar_movies = top_N_similar_movies[0:5]\n",
    "#         print(\"PAIR : \", \"first element =\" , similar_movies[0][0], \"second element =\", similar_movies[0][1])\n",
    "        \n",
    "#         #Predicting the rating with Pearson correlation\n",
    "#         pearson_denominator = sum([pair[1] for pair in similar_movies])\n",
    "#         pearson_numerator = 0\n",
    "#         for i in range(0, 5):\n",
    "#             pearson_numerator += similar_movies[i][1] * original_rating[similar_movies[i][0] - 1][user_movie['userID'] - 1]\n",
    "        \n",
    "#         print(\"Predicting...\", pearson_numerator, \" / \", pearson_denominator)\n",
    "#         predictions_ratings.at[i, 'Rating'] = (pearson_numerator / pearson_denominator)\n",
    "#         print(\"Predicted rating : \", predictions_ratings.at[i, 'Rating'])\n",
    "    \n",
    "    return predictions_ratings\n",
    "            \n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "#####\n",
    "##\n",
    "## LATENT FACTORS\n",
    "##\n",
    "#####\n",
    "\n",
    "def predict_latent_factors(movies, users, ratings, predictions):\n",
    "    ## TO COMPLETE\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "#####\n",
    "##\n",
    "## FINAL PREDICTORS\n",
    "##\n",
    "#####\n",
    "\n",
    "def predict_final(movies, users, ratings, predictions):\n",
    "    ## TO COMPLETE\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "rating_predictions = predict_collaborative_filtering(movies_description,\n",
    "                                                     users_description, ratings_description, predictions_description)\n",
    "\n",
    "\n",
    "#####\n",
    "##\n",
    "## RANDOM PREDICTORS\n",
    "## //!!\\\\ TO CHANGE\n",
    "##\n",
    "#####\n",
    "\n",
    "#By default, predicted rate is a random classifier\n",
    "def predict_random(movies, users, ratings, predictions):\n",
    "    number_predictions = len(predictions)\n",
    "\n",
    "    return [[idx, randint(1, 5)] for idx in range(1, number_predictions + 1)]\n",
    "\n",
    "#####\n",
    "##\n",
    "## SAVE RESULTS\n",
    "##\n",
    "#####    \n",
    "\n",
    "\n",
    "# ## //!!\\\\ TO CHANGE by your prediction function\n",
    "# submission_read = pd.read_csv(submission_file)\n",
    "# submission_read.columns = ['id', 'rating']\n",
    "\n",
    "# predictions = predict_random(movies_description, users_description, ratings_description, predictions_description)\n",
    "# print(predictions)\n",
    "# predictions_df = pd.DataFrame(predictions, columns = ['Id', 'Rating'])\n",
    "\n",
    "# submission_result = submission_read.merge(predictions_df, how='left', left_on='id', right_on='Id')\n",
    "# submission_result.drop('id', axis=1, inplace=True)\n",
    "# submission_result.drop('rating', axis=1, inplace=True)\n",
    "# submission_result.head()\n",
    "# submission_result.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
