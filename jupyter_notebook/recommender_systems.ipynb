{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender systems\n",
    "\n",
    "- Implementing collaborative filtering and latent factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import random\n",
    "from random import randint\n",
    "from random import uniform\n",
    "print(np.version.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "### NOTES\n",
    "This file is an example of what your code should look like. It is written in Python 3.6.\n",
    "To know more about the expectations, please refer to the guidelines.\n",
    "\"\"\"\n",
    "\n",
    "#####\n",
    "##\n",
    "## DATA IMPORT\n",
    "##\n",
    "#####\n",
    "\n",
    "#Where data is located\n",
    "movies_file = '../data/movies.csv'\n",
    "users_file = '../data/users.csv'\n",
    "ratings_file = '../data/ratings.csv'\n",
    "predictions_file = '../data/predictions.csv'\n",
    "submission_file = '../data/submission.csv'\n",
    "\n",
    "# movies_file = r'/prediction/data/movies.csv'\n",
    "# users_file = '/prediction/data/users.csv'\n",
    "# ratings_file = '/prediction/data/ratings.csv'\n",
    "# predictions_file = '/prediction/data/predictions.csv'\n",
    "# submission_file = '/data/submission.csv'\n",
    "\n",
    "# Read the data using pandas\n",
    "movies_description = pd.read_csv(movies_file, delimiter=';', \n",
    "                                 dtype={'movieID':'int', 'year':'int', 'movie':'str'}, names=['movieID', 'year', 'movie'])\n",
    "users_description = pd.read_csv(users_file, delimiter=';', \n",
    "                                dtype={'userID':'int', 'gender':'str', 'age':'int', 'profession':'int'}, names=['userID', 'gender', 'age', 'profession'])\n",
    "ratings_description = pd.read_csv(ratings_file, delimiter=';', \n",
    "                                  dtype={'userID':'int', 'movieID':'int', 'rating':'float64'}, names=['userID', 'movieID', 'rating'])\n",
    "predictions_description = pd.read_csv(predictions_file, delimiter=';', \n",
    "                                      dtype={'userID':'int', 'movieID':'int'}, names=['userID', 'movieID'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS USELESS, THIS IS JUST TO SAVE MY CUSTOM PEARSON CORRELATION\n",
    "\n",
    "def pearson(r1, r2, min_len):\n",
    "     \n",
    "    # Removing all zero elements from both arrays\n",
    "    r1zero = np.where(r1 == 0)[0]\n",
    "    r2zero = np.where(r2 == 0)[0]\n",
    "    r_1 = np.delete(r1, r2zero)\n",
    "    r_2 = np.delete(r2, r1zero)\n",
    "    r_1 = r_1[r_1 != 0]\n",
    "    r_2 = r_2[r_2 != 0]\n",
    "#     print(\"RESULTS SHOULD BE: \", stats.pearsonr(r_1, r_2))\n",
    "\n",
    "\n",
    "    # test if arrays only have a few elements in common that aren't 0\n",
    "    if len(r_1) < min_len:\n",
    "        return None\n",
    "    \n",
    "    top = np.sum((r_1 - np.mean(r_1)) * (r_2 - np.mean(r_2)))\n",
    "    botleft = np.sqrt(np.sum(np.square(r_1 - np.mean(r_1))))\n",
    "    botright = np.sqrt(np.sum(np.square(r_2 - np.mean(r_2))))\n",
    "    if botleft * botright == 0:\n",
    "        return None\n",
    "    res = top / (botleft * botright)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "##\n",
    "## COLLABORATIVE FILTERING\n",
    "##\n",
    "#####\n",
    "\n",
    "# minimal elements to have a rating on for two movies to be considered a neighbour. \n",
    "# Otherwise a movie with one rating and rest all zeroes is a good neighbour to all movies with that rating by that one user\n",
    "\n",
    "def predict_collaborative_filtering(movies, users, ratings, predictions, neighbours, min_periods, print_output = False, corr = None):\n",
    "    \n",
    "    predictions_ratings = []\n",
    "    \n",
    "    \n",
    "#     Creating utility matrix 'u' : User x Movie -> Rating \n",
    "#     utility_matrix = ratings.pivot_table(index='movieID', columns='userID', values='rating',\n",
    "#                                          fill_value=0)\n",
    "    utility_matrix_none = ratings.pivot_table(index='userID', columns='movieID', values='rating',\n",
    "                                         fill_value=None)\n",
    " \n",
    "    # Add columns to the utility matrix for movies that are never rated\n",
    "    cols = utility_matrix_none.columns\n",
    "    for i in movies['movieID'].values:\n",
    "        if i not in cols:\n",
    "            utility_matrix_none[str(i)] = np.nan\n",
    "\n",
    "    if corr is None:    \n",
    "        corr = utility_matrix_none.corr(min_periods=min_periods)\n",
    "    \n",
    "    # I don't know why, but somehow saving this in a csv and loading it back up again fixes some errors\n",
    "    corr.to_csv(r'tempcorr.csv')\n",
    "    corr = pd.read_csv(r'tempcorr.csv')\n",
    "\n",
    "    if print_output:\n",
    "        print(\"\\n>>>UTILITY MATRIX\\n\")\n",
    "        print(utility_matrix_none)\n",
    "        print(\"\\n>>>CORR MATRIX\\n\")\n",
    "        print(corr)\n",
    "        print(\"\\n>>>TO PREDICT\")\n",
    "        print(predictions)\n",
    "        print(\"\\n\\n>>>STARTING PREDICTION \\n\\n\")\n",
    "    \n",
    "    # For every prediction to make (item/item, or movie/movie in this case)\n",
    "    for i in range(len(predictions)):\n",
    "        if i % 100 == 0:\n",
    "            print(i, \"/\", len(predictions))\n",
    "        user = predictions.iloc[i][0]\n",
    "        movie = predictions.iloc[i][1]\n",
    "          \n",
    "        \n",
    "        c = corr[['movieID', str(movie)]]\n",
    "        \n",
    "        # Sort the pearson correlation for all movies to the current movie to predict\n",
    "        sorted_pearson = c.sort_values(by = [str(movie)], axis = 0, ascending = False)\n",
    "        \n",
    "        # Delete the movie itself, it should not be checked\n",
    "        sorted_pearson = sorted_pearson[sorted_pearson.movieID != movie]\n",
    "        \n",
    "        # Get the movie id's of the sorted movies\n",
    "        sorted_movies = sorted_pearson['movieID'].values\n",
    "        sorted_corr = sorted_pearson[str(movie)].values\n",
    "        \n",
    "        # Add a certain amount of neirest neighbours, this amount is specified by the n_neighbours variable\n",
    "        relevant_ratings = []\n",
    "        for m in range(0, len(sorted_movies)):\n",
    "            mov = sorted_movies[m]\n",
    "            rating = utility_matrix_none.at[user, mov]\n",
    "            if not np.isnan(rating):\n",
    "                relevant_ratings.append((rating, sorted_corr[m]))\n",
    "                if len(relevant_ratings) == neighbours:\n",
    "                    break\n",
    "        \n",
    "        relevant_ratings = np.array(relevant_ratings)\n",
    "        \n",
    "        total_weight = np.sum(relevant_ratings, axis = 0)[1]\n",
    "        pred = 0\n",
    "        for j in range(len(relevant_ratings)):\n",
    "            pred += relevant_ratings[j, 0] * relevant_ratings[j, 1] / total_weight\n",
    "        \n",
    "        # If the rating can't be calculated, set it to 3 as average\n",
    "        if np.isnan(pred) or pred == 0:\n",
    "            pred = 3\n",
    "        \n",
    "        if print_output:\n",
    "            print(\"\\n>>>>>>>>>>>>STARTING PREDICTION NUMBER\", i + 1, \"\\nUser:\", user, \"\\nMovie:\", movie, \"\\n\")\n",
    "            print(\"\\n>>SORTED PEARSON CORRELATION MATRIX\\n\")\n",
    "            print(sorted_pearson)\n",
    "            print(\"\\n>>RELEVANT RATINGS AND THEIR WEIGHTS\\n\")\n",
    "            print(relevant_ratings)\n",
    "            print(\"\\n>>FINAL PREDICTION: \", pred)\n",
    "        predictions_ratings.append((i + 1, pred))\n",
    "    return predictions_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 90019\n",
      "100 / 90019\n",
      "200 / 90019\n",
      "300 / 90019\n",
      "400 / 90019\n",
      "500 / 90019\n",
      "600 / 90019\n"
     ]
    }
   ],
   "source": [
    "# Predict the submission and put it in csv\n",
    "min_elements_non_zero = 7\n",
    "n_neighbours = 7\n",
    "\n",
    "preds = predict_collaborative_filtering(movies_description,\n",
    "                                                     users_description, ratings_description, predictions_description, n_neighbours, min_elements_non_zero)\n",
    "print(preds)\n",
    "predictions_df = pd.DataFrame(preds, columns = ['Id', 'Rating'])\n",
    "predictions_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with test 1 / 169  Time =  09:54:45\n",
      "Done with test 2 / 169  Time =  09:55:03\n",
      "Done with test 3 / 169  Time =  09:55:22\n",
      "Done with test 4 / 169  Time =  09:55:41\n",
      "Done with test 5 / 169  Time =  09:56:00\n",
      "Done with test 6 / 169  Time =  09:56:20\n",
      "Done with test 7 / 169  Time =  09:56:38\n",
      "Done with test 8 / 169  Time =  09:56:57\n",
      "Done with test 9 / 169  Time =  09:57:16\n",
      "Done with test 10 / 169  Time =  09:57:34\n",
      "Done with test 11 / 169  Time =  09:57:53\n",
      "Done with test 12 / 169  Time =  09:58:12\n",
      "Done with test 13 / 169  Time =  09:58:31\n",
      "Done with test 14 / 169  Time =  09:59:43\n",
      "Done with test 15 / 169  Time =  10:00:01\n",
      "Done with test 16 / 169  Time =  10:00:19\n",
      "Done with test 17 / 169  Time =  10:00:37\n",
      "Done with test 18 / 169  Time =  10:00:55\n",
      "Done with test 19 / 169  Time =  10:01:13\n",
      "Done with test 20 / 169  Time =  10:01:32\n",
      "Done with test 21 / 169  Time =  10:01:51\n",
      "Done with test 22 / 169  Time =  10:02:09\n",
      "Done with test 23 / 169  Time =  10:02:27\n",
      "Done with test 24 / 169  Time =  10:02:45\n",
      "Done with test 25 / 169  Time =  10:03:03\n",
      "Done with test 26 / 169  Time =  10:03:20\n",
      "Done with test 27 / 169  Time =  10:04:30\n",
      "Done with test 28 / 169  Time =  10:04:48\n",
      "Done with test 29 / 169  Time =  10:05:05\n",
      "Done with test 30 / 169  Time =  10:05:24\n",
      "Done with test 31 / 169  Time =  10:05:42\n",
      "Done with test 32 / 169  Time =  10:05:59\n",
      "Done with test 33 / 169  Time =  10:06:17\n",
      "Done with test 34 / 169  Time =  10:06:34\n",
      "Done with test 35 / 169  Time =  10:06:52\n",
      "Done with test 36 / 169  Time =  10:07:10\n",
      "Done with test 37 / 169  Time =  10:07:28\n",
      "Done with test 38 / 169  Time =  10:07:46\n",
      "Done with test 39 / 169  Time =  10:08:03\n",
      "Done with test 40 / 169  Time =  10:09:09\n",
      "Done with test 41 / 169  Time =  10:09:26\n",
      "Done with test 42 / 169  Time =  10:09:42\n",
      "Done with test 43 / 169  Time =  10:09:59\n",
      "Done with test 44 / 169  Time =  10:10:16\n",
      "Done with test 45 / 169  Time =  10:10:33\n",
      "Done with test 46 / 169  Time =  10:10:50\n",
      "Done with test 47 / 169  Time =  10:11:09\n",
      "Done with test 48 / 169  Time =  10:11:29\n",
      "Done with test 49 / 169  Time =  10:11:49\n",
      "Done with test 50 / 169  Time =  10:12:09\n",
      "Done with test 51 / 169  Time =  10:12:29\n",
      "Done with test 52 / 169  Time =  10:12:49\n",
      "Done with test 53 / 169  Time =  10:14:10\n",
      "Done with test 54 / 169  Time =  10:14:29\n",
      "Done with test 55 / 169  Time =  10:14:48\n",
      "Done with test 56 / 169  Time =  10:15:08\n",
      "Done with test 57 / 169  Time =  10:15:27\n",
      "Done with test 58 / 169  Time =  10:15:48\n",
      "Done with test 59 / 169  Time =  10:16:08\n",
      "Done with test 60 / 169  Time =  10:16:28\n",
      "Done with test 61 / 169  Time =  10:16:49\n",
      "Done with test 62 / 169  Time =  10:17:09\n",
      "Done with test 63 / 169  Time =  10:17:30\n",
      "Done with test 64 / 169  Time =  10:17:50\n",
      "Done with test 65 / 169  Time =  10:18:10\n",
      "Done with test 66 / 169  Time =  10:19:30\n",
      "Done with test 67 / 169  Time =  10:19:49\n",
      "Done with test 68 / 169  Time =  10:20:10\n",
      "Done with test 69 / 169  Time =  10:20:30\n",
      "Done with test 70 / 169  Time =  10:20:50\n",
      "Done with test 71 / 169  Time =  10:21:09\n",
      "Done with test 72 / 169  Time =  10:21:25\n",
      "Done with test 73 / 169  Time =  10:21:41\n",
      "Done with test 74 / 169  Time =  10:21:57\n",
      "Done with test 75 / 169  Time =  10:22:13\n",
      "Done with test 76 / 169  Time =  10:22:29\n",
      "Done with test 77 / 169  Time =  10:22:44\n",
      "Done with test 78 / 169  Time =  10:23:00\n",
      "Done with test 79 / 169  Time =  10:24:04\n",
      "Done with test 80 / 169  Time =  10:24:19\n",
      "Done with test 81 / 169  Time =  10:24:35\n",
      "Done with test 82 / 169  Time =  10:24:50\n",
      "Done with test 83 / 169  Time =  10:25:09\n",
      "Done with test 84 / 169  Time =  10:25:25\n",
      "Done with test 85 / 169  Time =  10:25:41\n",
      "Done with test 86 / 169  Time =  10:25:57\n",
      "Done with test 87 / 169  Time =  10:26:14\n",
      "Done with test 88 / 169  Time =  10:26:33\n",
      "Done with test 89 / 169  Time =  10:26:53\n",
      "Done with test 90 / 169  Time =  10:27:12\n",
      "Done with test 91 / 169  Time =  10:27:32\n",
      "Done with test 92 / 169  Time =  10:28:54\n",
      "Done with test 93 / 169  Time =  10:29:13\n",
      "Done with test 94 / 169  Time =  10:29:33\n",
      "Done with test 95 / 169  Time =  10:29:52\n",
      "Done with test 96 / 169  Time =  10:30:11\n",
      "Done with test 97 / 169  Time =  10:30:31\n",
      "Done with test 98 / 169  Time =  10:30:49\n",
      "Done with test 99 / 169  Time =  10:31:08\n",
      "Done with test 100 / 169  Time =  10:31:27\n",
      "Done with test 101 / 169  Time =  10:31:46\n",
      "Done with test 102 / 169  Time =  10:32:05\n",
      "Done with test 103 / 169  Time =  10:32:24\n",
      "Done with test 104 / 169  Time =  10:32:43\n",
      "Done with test 105 / 169  Time =  10:34:04\n",
      "Done with test 106 / 169  Time =  10:34:23\n",
      "Done with test 107 / 169  Time =  10:34:43\n",
      "Done with test 108 / 169  Time =  10:35:02\n",
      "Done with test 109 / 169  Time =  10:35:21\n",
      "Done with test 110 / 169  Time =  10:35:39\n",
      "Done with test 111 / 169  Time =  10:35:58\n",
      "Done with test 112 / 169  Time =  10:36:16\n",
      "Done with test 113 / 169  Time =  10:36:33\n",
      "Done with test 114 / 169  Time =  10:36:50\n",
      "Done with test 115 / 169  Time =  10:37:07\n",
      "Done with test 116 / 169  Time =  10:37:23\n",
      "Done with test 117 / 169  Time =  10:37:39\n",
      "Done with test 118 / 169  Time =  10:38:48\n",
      "Done with test 119 / 169  Time =  10:39:04\n",
      "Done with test 120 / 169  Time =  10:39:19\n",
      "Done with test 121 / 169  Time =  10:39:36\n",
      "Done with test 122 / 169  Time =  10:39:51\n",
      "Done with test 123 / 169  Time =  10:40:07\n",
      "Done with test 124 / 169  Time =  10:40:23\n",
      "Done with test 125 / 169  Time =  10:40:39\n",
      "Done with test 126 / 169  Time =  10:40:55\n",
      "Done with test 127 / 169  Time =  10:41:10\n",
      "Done with test 128 / 169  Time =  10:41:25\n",
      "Done with test 129 / 169  Time =  10:41:41\n",
      "Done with test 130 / 169  Time =  10:41:59\n",
      "Done with test 131 / 169  Time =  10:43:09\n",
      "Done with test 132 / 169  Time =  10:43:24\n",
      "Done with test 133 / 169  Time =  10:43:40\n",
      "Done with test 134 / 169  Time =  10:43:58\n",
      "Done with test 135 / 169  Time =  10:44:14\n",
      "Done with test 136 / 169  Time =  10:44:30\n",
      "Done with test 137 / 169  Time =  10:44:47\n",
      "Done with test 138 / 169  Time =  10:45:03\n",
      "Done with test 139 / 169  Time =  10:45:19\n",
      "Done with test 140 / 169  Time =  10:45:35\n",
      "Done with test 141 / 169  Time =  10:45:52\n",
      "Done with test 142 / 169  Time =  10:46:08\n",
      "Done with test 143 / 169  Time =  10:46:24\n",
      "Done with test 144 / 169  Time =  10:47:31\n",
      "Done with test 145 / 169  Time =  10:47:47\n",
      "Done with test 146 / 169  Time =  10:48:02\n",
      "Done with test 147 / 169  Time =  10:48:18\n",
      "Done with test 148 / 169  Time =  10:48:34\n",
      "Done with test 149 / 169  Time =  10:48:50\n",
      "Done with test 150 / 169  Time =  10:49:05\n",
      "Done with test 151 / 169  Time =  10:49:21\n",
      "Done with test 152 / 169  Time =  10:49:36\n",
      "Done with test 153 / 169  Time =  10:49:52\n",
      "Done with test 154 / 169  Time =  10:50:08\n",
      "Done with test 155 / 169  Time =  10:50:24\n",
      "Done with test 156 / 169  Time =  10:50:39\n",
      "Done with test 157 / 169  Time =  10:51:48\n",
      "Done with test 158 / 169  Time =  10:52:04\n",
      "Done with test 159 / 169  Time =  10:52:20\n",
      "Done with test 160 / 169  Time =  10:52:40\n",
      "Done with test 161 / 169  Time =  10:52:57\n",
      "Done with test 162 / 169  Time =  10:53:14\n",
      "Done with test 163 / 169  Time =  10:53:31\n",
      "Done with test 164 / 169  Time =  10:53:49\n",
      "Done with test 165 / 169  Time =  10:54:07\n",
      "Done with test 166 / 169  Time =  10:54:23\n",
      "Done with test 167 / 169  Time =  10:54:41\n",
      "Done with test 168 / 169  Time =  10:54:59\n",
      "Done with test 169 / 169  Time =  10:55:16\n"
     ]
    }
   ],
   "source": [
    "#delete import later\n",
    "from datetime import datetime\n",
    "\n",
    "# Creates random test prediction scores (so we can test our RMSE)\n",
    "def create_random_tests(ratings, amount, seed):\n",
    "    if seed != -1:\n",
    "        random.seed(seed)\n",
    "    predictions = []\n",
    "    solutions = []\n",
    "    for i in range(amount):\n",
    "        r = random.randint(0, 910189)\n",
    "        predictions.append(ratings.loc[r][0:2])\n",
    "        solutions.append(ratings.loc[r][2])\n",
    "    predictions_df = pd.DataFrame(predictions, columns = ['userID', 'movieID'], dtype = 'int')\n",
    "    \n",
    "    return (predictions_df, solutions)\n",
    "\n",
    "\n",
    "# Calculates root mean squared error\n",
    "def rmse(pred, sol):\n",
    "    return np.sqrt(((np.array(pred) - np.array(sol)) ** 2).mean())\n",
    "\n",
    "# Runs the create tests method, and then executes these tests\n",
    "def run_tests(amount, seed = -1, neighbours = [5], min_periods = [5]):\n",
    "    (random_test_predictions, random_test_solutions) = create_random_tests(ratings_description, amount, seed = seed)\n",
    "    test_results = []\n",
    "    \n",
    "    total_tests = len(neighbours) * len(min_periods)\n",
    "    curr_test = 1\n",
    "    # For each pair of neighbour/min_period, get the rmse of the result\n",
    "    for p in min_periods:\n",
    "        \n",
    "        # Make correlation matrix so it doesn't need to be calculated every time\n",
    "        utility_matrix_none = ratings_description.pivot_table(index='userID', columns='movieID', values='rating',\n",
    "                                         fill_value=None)\n",
    "        cols = utility_matrix_none.columns\n",
    "        for i in movies_description['movieID'].values:\n",
    "            if i not in cols:\n",
    "                utility_matrix_none[str(i)] = np.nan\n",
    "        corr = utility_matrix_none.corr(min_periods=p)\n",
    "        \n",
    "        \n",
    "        for n in neighbours:\n",
    "            predictions = predict_collaborative_filtering(movies_description,\n",
    "                                                     users_description, ratings_description, random_test_predictions, n, p, corr = corr)\n",
    "            predictions = [x[1] for x in predictions]\n",
    "            test_results.append((n, p, seed, rmse(predictions, random_test_solutions)))\n",
    "            \n",
    "            #print the time, so we know how long it takes, delete later\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            \n",
    "            print(\"Done with test\", curr_test, \"/\", total_tests, \" Time = \", current_time)\n",
    "            curr_test += 1\n",
    "            \n",
    "    return pd.DataFrame(test_results, columns = ['n_neighbours', 'min_periods', 'seed', 'rmse'], dtype = 'int')\n",
    "\n",
    "\n",
    "neighbours_to_test = [1, 2, 3, 4, 5]\n",
    "min_periods_to_test = [1, 2, 3, 4, 5]\n",
    "test_results = run_tests(100, seed = 42, neighbours = neighbours_to_test, min_periods = min_periods_to_test)\n",
    "test_results.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     '''\n",
    "#     Creating matrix for cosine similarity\n",
    "#     '''\n",
    "#     r = ratings \\\n",
    "#     .groupby('movieID', as_index=False, sort=False) \\\n",
    "#     .mean() \\\n",
    "#     .rename(columns={'movieID': 'movieID', 'rating' : 'mean_rating'})\n",
    "#     r.drop('userID', axis=1, inplace=True)\n",
    "    \n",
    "#     new_r = ratings.merge(r, how='left', on='movieID', sort=False)\n",
    "#     new_r['centered_cosine'] = new_r['rating'] - new_r['mean_rating']\n",
    "    \n",
    "#     centered_cosine = new_r \\\n",
    "#     .pivot_table(index='movieID', columns='userID', values='centered_cosine') \\\n",
    "#     .fillna(0)\n",
    "    \n",
    "    \n",
    "#     all_movies_numpy = centered_cosine.values\n",
    "#     for i, row in centered_cosine.iterrows():\n",
    "#         if(i in range_missing):\n",
    "#             all_movies_numpy = np.vstack([all_movies_numpy, row.values])\n",
    "            \n",
    "            \n",
    "#     '''\n",
    "#     Cosine similarity - find similar users for a certain user based on |N|,\n",
    "#     also making a prediction with Pearson correlation\n",
    "#     '''\n",
    "#     for i, user_movie in predictions.iterrows():\n",
    "#         print(\"CURRENT MOVIE : \", user_movie['movieID'])\n",
    "#         current_movie = all_movies_numpy[user_movie['movieID'] - 1]\n",
    "#         current_rating = original_rating[user_movie['movieID'] - 1][user_movie['userID'] - 1]\n",
    "#         if(current_rating > 0):\n",
    "#              predictions_ratings.at[i, 'Rating'] = current_rating\n",
    "#              continue\n",
    "        \n",
    "#         current_denominator = np.sqrt(sum([np.square(x) for x in current_movie]))\n",
    "#         top_N_similar_movies = []\n",
    "        \n",
    "#         # Computing similarities to current movie that we want to predict for particular user\n",
    "#         for id_movie, movie in enumerate(all_movies_numpy):\n",
    "            \n",
    "#             numerator = [x*y for x, y in zip(current_movie, movie)]\n",
    "#             other_denominator = np.sqrt(sum([np.square(x) for x in movie]))\n",
    "#             costheta = sum(numerator) / (current_denominator * other_denominator)\n",
    "#             top_N_similar_movies.append((id_movie + 1, costheta))\n",
    "            \n",
    "#         # Get N similar items\n",
    "#         top_N_similar_movies.sort(key=lambda pair: pair[1], reverse=True)\n",
    "#         similar_movies = top_N_similar_movies[0:5]\n",
    "#         print(\"PAIR : \", \"first element =\" , similar_movies[0][0], \"second element =\", similar_movies[0][1])\n",
    "        \n",
    "#         #Predicting the rating with Pearson correlation\n",
    "#         pearson_denominator = sum([pair[1] for pair in similar_movies])\n",
    "#         pearson_numerator = 0\n",
    "#         for i in range(0, 5):\n",
    "#             pearson_numerator += similar_movies[i][1] * original_rating[similar_movies[i][0] - 1][user_movie['userID'] - 1]\n",
    "        \n",
    "#         print(\"Predicting...\", pearson_numerator, \" / \", pearson_denominator)\n",
    "#         predictions_ratings.at[i, 'Rating'] = (pearson_numerator / pearson_denominator)\n",
    "#         print(\"Predicted rating : \", predictions_ratings.at[i, 'Rating'])\n",
    "    \n",
    "    return predictions_ratings\n",
    "            \n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "#####\n",
    "##\n",
    "## LATENT FACTORS\n",
    "##\n",
    "#####\n",
    "\n",
    "def predict_latent_factors(movies, users, ratings, predictions):\n",
    "    ## TO COMPLETE\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "#####\n",
    "##\n",
    "## FINAL PREDICTORS\n",
    "##\n",
    "#####\n",
    "\n",
    "def predict_final(movies, users, ratings, predictions):\n",
    "    ## TO COMPLETE\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "rating_predictions = predict_collaborative_filtering(movies_description,\n",
    "                                                     users_description, ratings_description, predictions_description)\n",
    "\n",
    "\n",
    "#####\n",
    "##\n",
    "## RANDOM PREDICTORS\n",
    "## //!!\\\\ TO CHANGE\n",
    "##\n",
    "#####\n",
    "\n",
    "#By default, predicted rate is a random classifier\n",
    "def predict_random(movies, users, ratings, predictions):\n",
    "    number_predictions = len(predictions)\n",
    "\n",
    "    return [[idx, randint(1, 5)] for idx in range(1, number_predictions + 1)]\n",
    "\n",
    "#####\n",
    "##\n",
    "## SAVE RESULTS\n",
    "##\n",
    "#####    \n",
    "\n",
    "\n",
    "# ## //!!\\\\ TO CHANGE by your prediction function\n",
    "# submission_read = pd.read_csv(submission_file)\n",
    "# submission_read.columns = ['id', 'rating']\n",
    "\n",
    "# predictions = predict_random(movies_description, users_description, ratings_description, predictions_description)\n",
    "# print(predictions)\n",
    "# predictions_df = pd.DataFrame(predictions, columns = ['Id', 'Rating'])\n",
    "\n",
    "# submission_result = submission_read.merge(predictions_df, how='left', left_on='id', right_on='Id')\n",
    "# submission_result.drop('id', axis=1, inplace=True)\n",
    "# submission_result.drop('rating', axis=1, inplace=True)\n",
    "# submission_result.head()\n",
    "# submission_result.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
